{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Lambda, TimeDistributed, \\\n",
    "                                    Add, Conv1D, Dropout, Concatenate, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "for physical_device in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)\n",
    "\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sweet/1-workdir/nlp_attention/en_vi_attention_nlp/src\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dir = \"/home/sweet/1-workdir/nlp_attention/en_vi_data_preprocess/src/\"\n",
    "db_file = \"train-test.json\"\n",
    "dict_file = \"dictionary.json\"\n",
    "\n",
    "train_X = []\n",
    "train_Y = []\n",
    "\n",
    "test_X = []\n",
    "test_Y = []\n",
    "\n",
    "with open(db_dir + db_file, 'r') as f_db, open(db_dir + dict_file, 'r') as f_dict:\n",
    "    db = json.load(f_db)\n",
    "    dictionary = json.load(f_dict)\n",
    "    \n",
    "train_X = db['train_X']\n",
    "train_Y = db['train_Y']\n",
    "test_X = db['test_X']\n",
    "test_Y = db['test_Y']\n",
    "\n",
    "dictionary_from = dictionary['from']['dictionary']\n",
    "rev_dictionary_from = dictionary['from']['rev_dictionary']\n",
    "\n",
    "dictionary_to = dictionary['to']['dictionary']\n",
    "rev_dictionary_to = dictionary['to']['rev_dictionary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = dictionary_from['GO']\n",
    "PAD = dictionary_from['PAD']\n",
    "EOS = dictionary_from['EOS']\n",
    "UNK = dictionary_from['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 133317/133317 [00:00<00:00, 2409019.74it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(train_X))):\n",
    "    train_X[i] += ' EOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2821/2821 [00:00<00:00, 1196252.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(test_X))):\n",
    "    test_X[i] += ' EOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_positional_encoding_matrix(length, d_model):\n",
    "    pe = np.zeros((length, d_model), dtype=np.float32)\n",
    "    positions = np.arange(length, dtype=np.float32)\n",
    "    denom = np.power(10000.0, np.arange(0, d_model, 2, np.float32) / d_model)\n",
    "\n",
    "    for i in range(d_model):\n",
    "        if i % 2 == 0:\n",
    "            pe[:,i] = np.sin(positions/denom[i//2])\n",
    "        else:\n",
    "            pe[:,i] = np.cos(positions/denom[i//2])\n",
    "    \n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_seq(x, null_token_value=0):\n",
    "    mask = K.cast(K.not_equal(x, null_token_value), 'float32')\n",
    "    pos = K.cumsum(K.ones_like(x, 'float32'), 1)\n",
    "    return pos * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(args, null_token_value):\n",
    "    y_pred, y_true = args\n",
    "\n",
    "    y_true_id = K.cast(y_true, \"int32\")\n",
    "\n",
    "    mask = K.cast(K.equal(y_true_id, null_token_value), K.floatx())\n",
    "    mask = 1.0 - mask\n",
    "    loss = K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True) * mask\n",
    "\n",
    "    # take average w.r.t. the number of unmasked entries\n",
    "    return K.sum(loss) / K.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_accuracy(args, null_token_value):\n",
    "    y_pred, y_true = args\n",
    "\n",
    "    y_true = K.cast(y_true, \"int32\")\n",
    "    mask = 1.0 - K.cast(K.equal(y_true, null_token_value), K.floatx())\n",
    "\n",
    "    y_pred = K.cast(K.argmax(y_pred, axis=-1), \"int32\")\n",
    "    correct = K.cast(\n",
    "        K.equal(y_pred, y_true),\n",
    "        K.floatx()\n",
    "    )\n",
    "    correct = K.sum(correct * mask, -1) / K.sum(mask, -1)\n",
    "\n",
    "    return K.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(object):\n",
    "    # def __init__(self, d_model=512, d_ff=2048, **kwargs):\n",
    "    def __init__(self, d_model=512, d_ff=512, **kwargs):\n",
    "        self._d_model = d_model\n",
    "        self._d_ff = d_ff\n",
    "\n",
    "        self._conv1 = Conv1D(self._d_ff, kernel_size=1, activation=\"relu\")\n",
    "        self._conv2 = Conv1D(self._d_model, kernel_size=1)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        intermediate_x = self._conv1(x)\n",
    "        return self._conv2(intermediate_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(object):\n",
    "    def __init__(self, h=8, d_k=64, d_v=64, d_model=512, d_inner_hid=2048):\n",
    "        self._mha = MultiHeadAttention(n_head=h, d_k=d_k, d_v=d_v, d_model=d_model)\n",
    "        self._ln_a = LayerNormalization()\n",
    "        self._psfw = PositionWiseFeedForward(d_model=d_model, d_ff=d_inner_hid)\n",
    "        self._ln_b = LayerNormalization()\n",
    "        self._add_a = Add()\n",
    "        self._add_b = Add()\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        y = self._mha(x, x, x)\n",
    "        y = self._add_a([x, y])\n",
    "        x = self._ln_a(y)\n",
    "        \n",
    "        y = self._psfw(x)\n",
    "        y = self._add_b([x, y])\n",
    "        x = self._ln_b(y)\n",
    "        \n",
    "        return x   \n",
    "\n",
    "class Encoder(object):\n",
    "\tdef __init__(self, embedding, position_embedding, \n",
    "                 n=6, h=8, d_k=64, d_v=64, d_model=512, d_inner_hid=2048, null_token_value=0):\n",
    "\t\tself._embedding = embedding\n",
    "\t\tself._position_embedding = position_embedding\n",
    "\t\tself._n = n\n",
    "\t\tself._position_encoding = Lambda(get_pos_seq, arguments={\"null_token_value\": null_token_value})\n",
    "\t\t\n",
    "\t\tself._layers = [EncoderLayer(h=h, d_k=d_k, d_v=d_v, d_model=d_model, d_inner_hid=d_inner_hid) for _ in range(n)]\n",
    "\t\n",
    "\tdef __call__(self, x):\n",
    "\t\tx_embedded = self._embedding(x)\n",
    "\t\tpos_encoding = self._position_encoding(x)\n",
    "\t\tpos_encoding_embedded = self._position_embedding(pos_encoding)\n",
    "\t\tx = Add()([x_embedded, pos_encoding_embedded])\n",
    "\t\t\n",
    "\t\tfor layer in self._layers:\n",
    "\t\t\tx = layer(x)\n",
    "\t\t\t\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(object):\n",
    "\tdef __init__(self, h=8, d_k=64, d_v=64, d_model=512, d_inner_hid=2048, return_attention=True):\n",
    "\t\tself._mha_a = MultiHeadAttention(n_head=h, d_k=d_k, d_v=d_v, d_model=d_model, return_attention=return_attention)\n",
    "\t\tself._mha_b = MultiHeadAttention(n_head=h, d_k=d_k, d_v=d_v, d_model=d_model, return_attention=return_attention)\n",
    "\t\tself._psfw = PositionWiseFeedForward(d_model=d_model, d_ff=d_inner_hid)\n",
    "\t\tself._ln_a = LayerNormalization()\n",
    "\t\tself._ln_b = LayerNormalization()\n",
    "\t\tself._ln_c = LayerNormalization()\n",
    "\t\tself._add_a = Add()\n",
    "\t\tself._add_b = Add()\n",
    "\t\tself._add_c = Add()\n",
    "\t\tself._return_attention = return_attention\n",
    "\t\t\n",
    "\tdef __call__(self, x, encoder_output):\n",
    "\t\ty, self_atn = self._mha_a(x, x, x)\n",
    "\t\ty = self._add_a([x, y])\n",
    "\t\tx = self._ln_a(y)\n",
    "\t\t\n",
    "\t\ty, enc_atn = self._mha_b(x, encoder_output, encoder_output)\n",
    "\t\ty = self._add_b([x, y])\n",
    "\t\tx = self._ln_b(y)\n",
    "\t\t\n",
    "\t\ty = self._psfw(x)\n",
    "\t\ty = self._add_c([x, y])\n",
    "\t\tx = self._ln_c(y)\n",
    "\t\t\n",
    "\t\tif self._return_attention:\n",
    "\t\t\treturn [x, self_atn, enc_atn]\n",
    "\t\telse:\n",
    "\t\t\treturn x \n",
    "\n",
    "class Decoder(object):\n",
    "\tdef __init__(self, embedding, position_embedding, \n",
    "                 n=6, h=8, d_k=64, d_v=64, d_model=512, d_inner_hid=2048, null_token_value=0):\n",
    "\t\tself._embedding = embedding\n",
    "\t\tself._position_embedding = position_embedding\n",
    "\t\tself._n = n\n",
    "\t\tself._position_encoding = Lambda(get_pos_seq, arguments={\"null_token_value\": null_token_value})\n",
    "\t\t\n",
    "\t\tself._layers = [DecoderLayer(h=h, d_k=d_k, d_v=d_v, d_model=d_model, d_inner_hid=d_inner_hid) for _ in range(n)]\n",
    "\t\n",
    "\tdef __call__(self, x, encoder_output, return_attention=False):\n",
    "\t\tx_embedded = self._embedding(x)\n",
    "\t\tpos_encoding = self._position_encoding(x)\n",
    "\t\tpos_encoding_embedded = self._position_embedding(pos_encoding)\n",
    "\t\tx = Add()([x_embedded, pos_encoding_embedded])\n",
    "\n",
    "\t\tself_atts = []\n",
    "\t\tenc_atts = []\n",
    "\n",
    "\t\tfor layer in self._layers:\n",
    "\t\t\tx, self_att, enc_att = layer(x, encoder_output)\n",
    "\n",
    "\t\t\tif return_attention: \n",
    "\t\t\t\tself_atts.append(self_att)\n",
    "\t\t\t\tenc_atts.append(enc_att)\n",
    "\t\t \n",
    "\t\tif return_attention: \n",
    "\t\t\treturn [x, self_atts, enc_atts]\n",
    "\t\telse:\n",
    "\t\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_encoders=6\n",
    "num_multi_heads=8\n",
    "d_k=64\n",
    "d_v=64\n",
    "d_model=512\n",
    "optimizer=\"adam\"\n",
    "null_token_value=0\n",
    "source_vocab_size = len(dictionary_from)\n",
    "target_vocab_size = len(dictionary_to)\n",
    "share_word_embedding=False\n",
    "MAXIMUM_TEXT_LENGTH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build transformer\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    # define some placeholders for source and target\n",
    "    source_input = Input(shape=(None,), name=\"source_input\")\n",
    "    target_input = Input(shape=(None,), name=\"target_input\")\n",
    "\n",
    "    # define some placeholders for encoder's input, decoder's input, and decoder's output \n",
    "    enc_input = Lambda(lambda x:x[:,1:])(source_input)\n",
    "    dec_input  = Lambda(lambda x:x[:,:-1])(target_input)\n",
    "    dec_target_output = Lambda(lambda x:x[:,1:])(target_input)\n",
    "\n",
    "    # create embedding\n",
    "\n",
    "    # weights=[_get_positional_encoding_matrix(max_length, d_model)]\n",
    "    source_word_embedding = Embedding(source_vocab_size, d_model, name=\"source_embedding\")\n",
    "\n",
    "    if share_word_embedding:\n",
    "        target_word_embedding = source_word_embedding\n",
    "    else:\n",
    "        target_word_embedding = Embedding(target_vocab_size, d_model, name=\"target_embedding\")\n",
    "\n",
    "    # embedding for the position encoding\n",
    "    pos_enc_mat = get_positional_encoding_matrix(MAXIMUM_TEXT_LENGTH, d_model)\n",
    "    position_encoding = Embedding(MAXIMUM_TEXT_LENGTH, d_model, trainable=False, \n",
    "                                  weights=[pos_enc_mat], \n",
    "                                  name=\"position_embedding\")\n",
    "\n",
    "    enc = Encoder(source_word_embedding, position_encoding, \n",
    "                  n=num_encoders, h=num_multi_heads, d_k=d_k, d_v=d_v, d_model=d_model, d_inner_hid=512)\n",
    "    dec = Decoder(target_word_embedding, position_encoding, \n",
    "                  n=num_encoders, h=num_multi_heads, d_k=d_k, d_v=d_v, d_model=d_model, d_inner_hid=512)\n",
    "\n",
    "    enc_output = enc(enc_input)\n",
    "    dec_output = dec(dec_input, enc_output)\n",
    "\n",
    "    # lin_dense = TimeDistributed(Dense(d_model))\n",
    "    fin_output = TimeDistributed(Dense(target_vocab_size, activation=None, use_bias=False), name=\"output\") # \"softmax\"\n",
    "\n",
    "    # lin_dense_out = lin_dense(dec_output)\n",
    "    fin_output_out = fin_output(dec_output) # lin_dense_out)\n",
    "\n",
    "    accuracy = Lambda(get_accuracy, arguments={\"null_token_value\": null_token_value})([fin_output_out, dec_target_output])\n",
    "    loss = Lambda(get_loss, arguments={\"null_token_value\": null_token_value})([fin_output_out, dec_target_output])\n",
    "\n",
    "    train_model = Model(inputs=[source_input, target_input], outputs=loss)\n",
    "    train_model.add_loss([loss])\n",
    "    train_model.compile(optimizer, None)\n",
    "    train_model.metrics_names.append('accuracy')\n",
    "    train_model.metrics.append(accuracy)\n",
    "\n",
    "    inference_model = Model([source_input, target_input], fin_output_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 2 required positional arguments: 'k' and 'v'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-a16e11ed6d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m training_model, inference_model = create_model(source_vocab_size, target_vocab_size, MAXIMUM_TEXT_LENGTH,\n\u001b[0;32m----> 2\u001b[0;31m                                                 n=2, d_model=256, h=4, optimizer=Adam(0.001, 0.9, 0.98, epsilon=1e-9))\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtraining_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/1-workdir/nlp_attention/en_vi_attention_nlp/src/model.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(source_vocabulary_size, target_vocabulary_size, max_length, share_word_embedding, n, h, d_k, d_v, d_model, optimizer, null_token_value)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0msource_vocabulary_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_vocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_vocabulary_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_vocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshare_word_embedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshare_word_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         n=n, h=h, d_k=d_k, d_v=d_v,d_model=d_model, optimizer=optimizer, null_token_value=null_token_value)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnull_token_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/1-workdir/nlp_attention/en_vi_attention_nlp/src/model.py\u001b[0m in \u001b[0;36mbuild_transformer\u001b[0;34m(source_vocabulary_size, target_vocabulary_size, max_length, share_word_embedding, n, h, d_k, d_v, d_model, optimizer, null_token_value)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_word_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_v\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_inner_hid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m     \u001b[0menc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0mdec_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdec_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/1-workdir/nlp_attention/en_vi_attention_nlp/src/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/1-workdir/nlp_attention/en_vi_attention_nlp/src/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ln_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __call__() missing 2 required positional arguments: 'k' and 'v'"
     ]
    }
   ],
   "source": [
    "training_model, inference_model = create_model(source_vocab_size, target_vocab_size, MAXIMUM_TEXT_LENGTH,\n",
    "                                                n=2, d_model=256, h=4, optimizer=Adam(0.001, 0.9, 0.98, epsilon=1e-9))\n",
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_idx(corpus, dic):\n",
    "    X = []\n",
    "    for i in corpus:\n",
    "        ints = []\n",
    "        for k in i.split():\n",
    "            ints.append(dic.get(k,UNK))\n",
    "        X.append(ints)\n",
    "    return X\n",
    "\n",
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    padded_seqs = []\n",
    "    seq_lens = []\n",
    "    max_sentence_len = max([len(sentence) for sentence in sentence_batch])\n",
    "    for sentence in sentence_batch:\n",
    "        padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
    "        seq_lens.append(len(sentence))\n",
    "    return np.array(padded_seqs), np.array(seq_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = str_idx(train_X, dictionary_from)\n",
    "test_X = str_idx(test_X, dictionary_from)\n",
    "train_Y = str_idx(train_Y, dictionary_to)\n",
    "test_Y = str_idx(test_Y, dictionary_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_train_X, _ = pad_sentence_batch(train_X, PAD)\n",
    "padded_train_Y, _ = pad_sentence_batch(train_Y, PAD)\n",
    "print(padded_train_X.shape, padded_train_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_test_X, _ = pad_sentence_batch(test_X, PAD)\n",
    "padded_test_Y, _ = pad_sentence_batch(test_Y, PAD)\n",
    "print(padded_test_X.shape, padded_test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    BUFFER_SIZE = padded_train_X.shape[0]\n",
    "    BATCH_SIZE = 32\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((padded_train_X, padded_train_Y))\n",
    "\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=BUFFER_SIZE)\\\n",
    "                                    .batch(batch_size=BATCH_SIZE)\\\n",
    "                                    .prefetch(buffer_size=AUTOTUNE)\n",
    "    train_gen = train_dataset.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    BUFFER_SIZE = padded_test_X.shape[0]\n",
    "    BATCH_SIZE = 32\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((padded_test_X, padded_test_Y))\n",
    "\n",
    "    validation_dataset = validation_dataset.shuffle(buffer_size=BUFFER_SIZE)\\\n",
    "                                    .batch(batch_size=BATCH_SIZE)\\\n",
    "                                    .prefetch(buffer_size=AUTOTUNE)\n",
    "    val_gen = validation_dataset.__iter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del train_X\n",
    "    del train_Y\n",
    "    del test_X\n",
    "    del test_Y\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for X, Y in train_gen:\n",
    "    train_model.fit([X, Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
